# TimescaleDB Documentation for HA-Momentum-Trading
================================================================================

## Table of Contents
1. [Database Overview](#database-overview)
2. [Installation & Setup](#installation--setup)
3. [Configuration](#configuration)
4. [Database Architecture](#database-architecture)
5. [Module Documentation](#module-documentation)
6. [Usage Examples](#usage-examples)
7. [Troubleshooting](#troubleshooting)
8. [Maintenance](#maintenance)

================================================================================

## Database Overview

### What is TimescaleDB?
TimescaleDB is a PostgreSQL extension optimized for time-series data. It's perfect for storing:
- Stock screener results over time
- OHLCV (Open, High, Low, Close, Volume) price data
- Technical indicators
- Trading signals

### Why TimescaleDB for This Project?
- **Time-series optimization**: Efficient storage and querying of time-based data
- **PostgreSQL compatibility**: Uses familiar SQL syntax
- **Automatic partitioning**: Data is automatically partitioned by time
- **Compression**: Reduces storage space for historical data
- **Fast queries**: Optimized for time-range queries

================================================================================

## Installation & Setup

### Prerequisites
- Docker Desktop installed and running
- Python 3.11+ with virtual environment
- Network access to localhost

### Step 1: Install Required Python Packages
```bash
pip install psycopg2-binary sqlalchemy python-dotenv asyncpg
```

### Step 2: Start TimescaleDB Container
```bash
# IMPORTANT: Using port 5433 to avoid conflicts with local PostgreSQL
docker run -d --name timescaledb -e POSTGRES_PASSWORD=password123 -p 5433:5432 timescale/timescaledb:latest-pg14
```

### Step 3: Create Database and Enable Extension
```bash
# Create the database
docker exec -it timescaledb psql -U postgres -c "CREATE DATABASE momentum_trading;"

# Enable TimescaleDB extension
docker exec -it timescaledb psql -U postgres -d momentum_trading -c "CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;"
```

### Step 4: Run Database Setup Script
```bash
python main/setup_database.py
```

================================================================================

## Configuration

### Environment Variables (.env file)
```env
# TimescaleDB Configuration
DB_HOST=127.0.0.1          # Use IPv4 to avoid IPv6 issues
DB_PORT=5433               # IMPORTANT: Port 5433 (not 5432) to avoid local PostgreSQL conflicts
DB_NAME=momentum_trading   # Database name
DB_USER=postgres           # Default PostgreSQL user
DB_PASSWORD=password123    # Simple password (no special characters)

# Connection Pool Settings
DB_POOL_SIZE=10           # Number of connections in pool
DB_MAX_OVERFLOW=20        # Maximum overflow connections
```

### Important Notes:
- **Port 5433**: We use 5433 instead of 5432 to avoid conflicts with local PostgreSQL installations
- **IPv4 Address**: Use 127.0.0.1 instead of localhost to avoid IPv6 connection issues
- **Simple Password**: Avoid special characters that might cause URL encoding issues

================================================================================

## Database Architecture

### Tables Overview

#### 1. screener_results
Stores stock screener results over time (PMH and RTH)
```sql
CREATE TABLE screener_results (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    timestamp TIMESTAMPTZ NOT NULL,      -- When the screen was run
    screener_type VARCHAR(10) NOT NULL,  -- 'PMH' or 'RTH'
    symbol VARCHAR(10) NOT NULL,         -- Stock symbol (e.g., 'AAPL')
    name VARCHAR(100),                   -- Company name
    change_percent FLOAT,                -- Percentage change
    price FLOAT,                         -- Current price
    volume INTEGER,                      -- Trading volume
    market_cap VARCHAR(20),              -- Market capitalization
    rank INTEGER                         -- Position in screener results
);
```

#### 2. ohlcv_data
Stores OHLCV price data with technical indicators
```sql
CREATE TABLE ohlcv_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    timestamp TIMESTAMPTZ NOT NULL,     -- Time of the price data
    symbol VARCHAR(10) NOT NULL,        -- Stock symbol
    timeframe VARCHAR(5) NOT NULL,      -- '1m', '10m', '1h', '1d', etc.
    
    -- OHLCV Data
    open_price FLOAT NOT NULL,
    high_price FLOAT NOT NULL,
    low_price FLOAT NOT NULL,
    close_price FLOAT NOT NULL,
    volume INTEGER NOT NULL,
    
    -- Technical Indicators (optional)
    sma_20 FLOAT,                       -- 20-period Simple Moving Average
    sma_50 FLOAT,                       -- 50-period Simple Moving Average
    ema_12 FLOAT,                       -- 12-period Exponential Moving Average
    ema_26 FLOAT,                       -- 26-period Exponential Moving Average
    rsi FLOAT,                          -- Relative Strength Index
    macd FLOAT,                         -- MACD line
    macd_signal FLOAT,                  -- MACD signal line
    macd_histogram FLOAT,               -- MACD histogram
    bollinger_upper FLOAT,              -- Bollinger Band upper
    bollinger_middle FLOAT,             -- Bollinger Band middle
    bollinger_lower FLOAT               -- Bollinger Band lower
);
```

#### 3. trading_signals
Stores trading signals generated from analysis
```sql
CREATE TABLE trading_signals (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    timestamp TIMESTAMPTZ NOT NULL,     -- When signal was generated
    symbol VARCHAR(10) NOT NULL,        -- Stock symbol
    signal_type VARCHAR(10) NOT NULL,   -- 'BUY', 'SELL', 'HOLD'
    confidence FLOAT,                   -- Signal confidence (0.0 to 1.0)
    strategy_name VARCHAR(50) NOT NULL, -- Name of strategy that generated signal
    timeframe VARCHAR(5) NOT NULL,      -- Timeframe of analysis
    entry_price FLOAT,                  -- Suggested entry price
    stop_loss FLOAT,                    -- Stop loss price
    take_profit FLOAT,                  -- Take profit price
    notes TEXT                          -- Additional notes
);
```

### Hypertables
All tables are converted to TimescaleDB hypertables for time-series optimization:
- Automatic partitioning by timestamp
- Optimized for time-range queries
- Better compression for older data

### Indexes
Optimized indexes for common query patterns:
- `timestamp` - For time-range queries
- `symbol` - For symbol-specific queries
- `symbol + timestamp` - For symbol time-series queries
- `screener_type` - For filtering PMH vs RTH results

================================================================================

## Module Documentation

### 1. connection.py - Database Connection Management

#### Purpose
Handles all database connections, configuration, and SQLAlchemy setup.

#### Key Components

##### Database Configuration
```python
DB_CONFIG = {
    'host': os.getenv('DB_HOST', '127.0.0.1'),
    'port': os.getenv('DB_PORT', '5433'),
    'database': os.getenv('DB_NAME', 'momentum_trading'),
    'username': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD', 'password123'),
    'pool_size': int(os.getenv('DB_POOL_SIZE', '10')),
    'max_overflow': int(os.getenv('DB_MAX_OVERFLOW', '20'))
}
```

##### SQLAlchemy Engine
```python
engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,        # Connection pooling
    pool_size=10,               # Number of persistent connections
    max_overflow=20,            # Additional connections when needed
    echo=False                  # Set to True for SQL logging
)
```

##### Key Functions
- `get_db()`: Dependency injection for database sessions
- `create_tables()`: Creates all database tables
- `test_connection()`: Tests database connectivity

### 2. models.py - Database Table Definitions

#### Purpose
Defines SQLAlchemy ORM models for all database tables.

#### Key Models

##### ScreenerResult Model
```python
class ScreenerResult(Base):
    __tablename__ = 'screener_results'
    
    # Primary key
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    
    # Time series key
    timestamp = Column(DateTime(timezone=True), server_default=func.now(), nullable=False)
    
    # Screener data
    screener_type = Column(String(10), nullable=False)  # 'PMH' or 'RTH'
    symbol = Column(String(10), nullable=False)
    # ... other columns
```

##### OHLCVData Model
```python
class OHLCVData(Base):
    __tablename__ = 'ohlcv_data'
    
    # Time series partitioning key
    timestamp = Column(DateTime(timezone=True), nullable=False)
    
    # OHLCV data
    open_price = Column(Float, nullable=False)
    high_price = Column(Float, nullable=False)
    # ... other OHLCV columns
    
    # Technical indicators (optional)
    sma_20 = Column(Float)
    rsi = Column(Float)
    # ... other indicators
```

#### Index Strategy
Each model includes optimized indexes:
```python
__table_args__ = (
    Index('idx_screener_timestamp', 'timestamp'),
    Index('idx_screener_symbol', 'symbol'),
    Index('idx_screener_symbol_timestamp', 'symbol', 'timestamp'),
)
```

### 3. operations.py - Database Operations

#### Purpose
Provides high-level database operations for inserting and querying data.

#### Key Class: DatabaseOperations

##### Context Manager Usage
```python
with DatabaseOperations() as db_ops:
    # Database operations here
    # Automatically handles session cleanup
    pass
```

##### Core Methods

###### setup_timescaledb()
```python
def setup_timescaledb(self):
    """
    Setup TimescaleDB hypertables for time-series data
    - Creates TimescaleDB extension
    - Converts tables to hypertables
    - Enables automatic partitioning
    """
```

###### insert_screener_results()
```python
def insert_screener_results(self, df: pd.DataFrame, screener_type: str) -> bool:
    """
    Insert screener results from DataFrame
    
    Args:
        df: DataFrame with columns ['Symbol', 'Name', 'Change %', 'Price', 'Volume', 'Market Cap']
        screener_type: 'PMH' or 'RTH'
    
    Returns:
        bool: Success status
    """
```

###### insert_ohlcv_data()
```python
def insert_ohlcv_data(self, symbol: str, timeframe: str, ohlcv_data: List[Dict]) -> bool:
    """
    Insert OHLCV data with indicators
    
    Args:
        symbol: Stock symbol (e.g., 'AAPL')
        timeframe: Time frame ('1m', '10m', etc.)
        ohlcv_data: List of dictionaries with OHLCV and indicator data
    
    Expected dictionary format:
    {
        'timestamp': datetime,
        'open': float,
        'high': float,
        'low': float,
        'close': float,
        'volume': int,
        'sma_20': float (optional),
        'rsi': float (optional),
        # ... other indicators
    }
    """
```

###### get_latest_screener_results()
```python
def get_latest_screener_results(self, screener_type: str, limit: int = 100) -> pd.DataFrame:
    """
    Get latest screener results
    
    Args:
        screener_type: 'PMH' or 'RTH'
        limit: Number of results to return
    
    Returns:
        pd.DataFrame: Screener results with columns:
        ['timestamp', 'symbol', 'name', 'change_percent', 'price', 'volume', 'market_cap', 'rank']
    """
```

###### get_ohlcv_data()
```python
def get_ohlcv_data(self, symbol: str, timeframe: str, days: int = 30) -> pd.DataFrame:
    """
    Get OHLCV data for a symbol
    
    Args:
        symbol: Stock symbol
        timeframe: Time frame ('1m', '10m', etc.)
        days: Number of days to retrieve
    
    Returns:
        pd.DataFrame: OHLCV data with all columns from ohlcv_data table
    """
```

##### Utility Methods
- `_safe_float()`: Safely converts strings to floats (handles %, $, commas)
- `_safe_int()`: Safely converts strings to integers (handles commas)

### 4. setup_database.py - Database Initialization

#### Purpose
One-time setup script to initialize the entire database system.

#### What It Does
1. **Tests Connection**: Verifies database connectivity
2. **Creates Tables**: Creates all SQLAlchemy tables
3. **Sets Up Hypertables**: Converts tables to TimescaleDB hypertables
4. **Tests Operations**: Validates basic database operations

#### Usage
```bash
python main/setup_database.py
```

#### Expected Output
```
==================================================
  TimescaleDB Setup for Momentum Trading
==================================================
ðŸš€ Starting TimescaleDB setup...
ðŸ“¡ Testing database connection...
âœ… Database connection successful!
ðŸ“‹ Creating database tables...
âœ… Tables created successfully!
âš¡ Setting up TimescaleDB hypertables...
âœ… TimescaleDB hypertables setup completed!
ðŸŽ‰ Database setup completed successfully!
```

================================================================================

## Usage Examples

### 1. Basic Connection Test
```python
from src.DB.connection import test_connection

if test_connection():
    print("Database is ready!")
else:
    print("Database connection failed")
```

### 2. Storing Screener Results
```python
import pandas as pd
from src.DB.operations import DatabaseOperations

# Assuming you have a DataFrame from your screener
df_pmh = pd.DataFrame({
    'Symbol': ['AAPL', 'MSFT', 'GOOGL'],
    'Name': ['Apple Inc.', 'Microsoft Corp.', 'Alphabet Inc.'],
    'Change %': [2.5, 1.8, 3.2],
    'Price': [150.00, 300.00, 2500.00],
    'Volume': [1000000, 800000, 600000],
    'Market Cap': ['2.5T', '2.3T', '1.7T']
})

with DatabaseOperations() as db_ops:
    success = db_ops.insert_screener_results(df_pmh, 'PMH')
    if success:
        print("Screener results stored successfully!")
```

### 3. Storing OHLCV Data
```python
from datetime import datetime
from src.DB.operations import DatabaseOperations

# Sample OHLCV data
ohlcv_data = [
    {
        'timestamp': datetime(2025, 9, 22, 9, 30),
        'open': 150.00,
        'high': 152.00,
        'low': 149.00,
        'close': 151.50,
        'volume': 1000000,
        'sma_20': 148.50,
        'rsi': 65.2
    },
    # ... more data points
]

with DatabaseOperations() as db_ops:
    success = db_ops.insert_ohlcv_data('AAPL', '1m', ohlcv_data)
    if success:
        print("OHLCV data stored successfully!")
```

### 4. Querying Data
```python
from src.DB.operations import DatabaseOperations

with DatabaseOperations() as db_ops:
    # Get latest PMH screener results
    pmh_results = db_ops.get_latest_screener_results('PMH', limit=10)
    print(f"Found {len(pmh_results)} PMH results")
    
    # Get OHLCV data for AAPL
    aapl_data = db_ops.get_ohlcv_data('AAPL', '1m', days=7)
    print(f"Found {len(aapl_data)} AAPL 1-minute bars")
```

### 5. Custom Queries with Raw SQL
```python
from src.DB.connection import SessionLocal
from sqlalchemy import text

with SessionLocal() as session:
    # Custom query example
    query = text("""
        SELECT symbol, AVG(change_percent) as avg_change
        FROM screener_results 
        WHERE timestamp >= NOW() - INTERVAL '7 days'
        AND screener_type = :screener_type
        GROUP BY symbol
        ORDER BY avg_change DESC
        LIMIT 10
    """)
    
    result = session.execute(query, {'screener_type': 'PMH'})
    top_performers = result.fetchall()
    
    for row in top_performers:
        print(f"{row.symbol}: {row.avg_change:.2f}%")
```

================================================================================

## Troubleshooting

### Common Issues and Solutions

#### 1. Connection Failed: Password Authentication
**Error**: `FATAL: password authentication failed for user "postgres"`

**Solutions**:
- Check `.env` file has correct password: `DB_PASSWORD=password123`
- Verify Docker container is using same password:
  ```bash
  docker exec -it timescaledb env | findstr POSTGRES
  ```
- Restart container if password was changed:
  ```bash
  docker restart timescaledb
  ```

#### 2. Port Already in Use
**Error**: `docker: Error response from daemon: port is already allocated`

**Solutions**:
- Check what's using port 5433:
  ```bash
  netstat -an | findstr :5433
  ```
- Stop conflicting service or use different port:
  ```bash
  docker run -d --name timescaledb -e POSTGRES_PASSWORD=password123 -p 5434:5432 timescale/timescaledb:latest-pg14
  ```
- Update `.env` file with new port

#### 3. IPv6 Connection Issues
**Error**: `connection to server at "localhost" (::1), port 5433 failed`

**Solutions**:
- Use IPv4 address in `.env`: `DB_HOST=127.0.0.1`
- Never use `localhost` - always use `127.0.0.1`

#### 4. Module Import Errors
**Error**: `ModuleNotFoundError: No module named 'DB'`

**Solutions**:
- Check Python path in scripts:
  ```python
  sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
  ```
- Run scripts from project root directory
- Ensure `__init__.py` files exist in directories

#### 5. Hypertable Creation Warnings
**Warning**: `cannot create a unique index without the column "timestamp"`

**Explanation**: This is normal! TimescaleDB requires timestamp in unique indexes.
**Action**: No action needed - tables work perfectly despite warning.

#### 6. Container Won't Start
**Troubleshooting Steps**:
```bash
# Check container status
docker ps -a

# Check container logs
docker logs timescaledb

# Remove and recreate if needed
docker stop timescaledb
docker rm timescaledb
docker run -d --name timescaledb -e POSTGRES_PASSWORD=password123 -p 5433:5432 timescale/timescaledb:latest-pg14
```

### Debugging Connection Issues

#### Test Connection Manually
```python
import psycopg2

try:
    conn = psycopg2.connect(
        host='127.0.0.1',
        port='5433',
        database='momentum_trading',
        user='postgres',
        password='password123'
    )
    print("âœ… Direct connection successful!")
    conn.close()
except Exception as e:
    print(f"âŒ Direct connection failed: {e}")
```

#### Check Docker Container Health
```bash
# Check if container is running
docker ps

# Check container logs for errors
docker logs timescaledb

# Connect directly to container
docker exec -it timescaledb psql -U postgres -d momentum_trading
```

================================================================================

## Maintenance

### Daily Operations

#### Start/Stop Database
```bash
# Start TimescaleDB container
docker start timescaledb

# Stop TimescaleDB container
docker stop timescaledb

# Check status
docker ps
```

#### Backup Database
```bash
# Create backup
docker exec -t timescaledb pg_dump -U postgres momentum_trading > backup.sql

# Restore backup
docker exec -i timescaledb psql -U postgres momentum_trading < backup.sql
```

### Monitoring

#### Check Database Size
```sql
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

#### Monitor Table Row Counts
```sql
SELECT 
    'screener_results' as table_name,
    COUNT(*) as row_count
FROM screener_results

UNION ALL

SELECT 
    'ohlcv_data' as table_name,
    COUNT(*) as row_count
FROM ohlcv_data

UNION ALL

SELECT 
    'trading_signals' as table_name,
    COUNT(*) as row_count
FROM trading_signals;
```

#### Check Recent Data
```sql
-- Check latest screener results
SELECT screener_type, COUNT(*), MAX(timestamp) as latest
FROM screener_results 
GROUP BY screener_type;

-- Check OHLCV data summary
SELECT symbol, timeframe, COUNT(*), MAX(timestamp) as latest
FROM ohlcv_data 
GROUP BY symbol, timeframe
ORDER BY latest DESC;
```

### Performance Optimization

#### Enable Compression (for older data)
```sql
-- Compress data older than 7 days
SELECT add_compression_policy('screener_results', INTERVAL '7 days');
SELECT add_compression_policy('ohlcv_data', INTERVAL '7 days');
```

#### Data Retention Policies
```sql
-- Keep screener results for 1 year
SELECT add_retention_policy('screener_results', INTERVAL '1 year');

-- Keep OHLCV data for 2 years
SELECT add_retention_policy('ohlcv_data', INTERVAL '2 years');
```

#### Continuous Aggregates (for analytics)
```sql
-- Create hourly aggregates for OHLCV data
CREATE MATERIALIZED VIEW ohlcv_hourly
WITH (timescaledb.continuous) AS
SELECT 
    time_bucket('1 hour', timestamp) AS hour,
    symbol,
    first(open_price, timestamp) AS open,
    max(high_price) AS high,
    min(low_price) AS low,
    last(close_price, timestamp) AS close,
    sum(volume) AS volume
FROM ohlcv_data
GROUP BY hour, symbol;
```

### Security Best Practices

#### Change Default Password
```bash
# In production, use a strong password
docker run -d --name timescaledb -e POSTGRES_PASSWORD='YourStrongPasswordHere' -p 5433:5432 timescale/timescaledb:latest-pg14
```

#### Network Security
- Use Docker networks to isolate database
- Consider using SSL/TLS for connections
- Restrict network access to database port

#### Backup Strategy
- Regular automated backups
- Store backups securely
- Test restore procedures

================================================================================

## Integration with Screeners

### PMH (Pre-Market Hours) Screener Integration
The PMH screener (`src/screener/PMH.py`) returns a DataFrame that's automatically compatible with the database:

```python
from src.screener.PMH import fetch_table_to_df
from src.DB.operations import DatabaseOperations

# Fetch PMH data
df_pmh = fetch_table_to_df()

# Store in database
with DatabaseOperations() as db_ops:
    success = db_ops.insert_screener_results(df_pmh, 'PMH')
```

### RTH (Regular Trading Hours) Screener Integration
Similar integration for RTH screener:

```python
from src.screener.RTH import fetch_table_to_df
from src.DB.operations import DatabaseOperations

# Fetch RTH data
df_rth = fetch_table_to_df()

# Store in database
with DatabaseOperations() as db_ops:
    success = db_ops.insert_screener_results(df_rth, 'RTH')
```

### Automated Data Collection
For continuous data collection, create a scheduler:

```python
import schedule
import time
from datetime import datetime
from src.screener.PMH import fetch_table_to_df as fetch_pmh
from src.screener.RTH import fetch_table_to_df as fetch_rth
from src.DB.operations import DatabaseOperations

def collect_pmh_data():
    """Collect pre-market data"""
    try:
        df = fetch_pmh()
        with DatabaseOperations() as db_ops:
            db_ops.insert_screener_results(df, 'PMH')
        print(f"PMH data collected at {datetime.now()}")
    except Exception as e:
        print(f"PMH collection failed: {e}")

def collect_rth_data():
    """Collect regular hours data"""
    try:
        df = fetch_rth()
        with DatabaseOperations() as db_ops:
            db_ops.insert_screener_results(df, 'RTH')
        print(f"RTH data collected at {datetime.now()}")
    except Exception as e:
        print(f"RTH collection failed: {e}")

# Schedule data collection
schedule.every().day.at("08:00").do(collect_pmh_data)  # Pre-market
schedule.every().day.at("09:30").do(collect_rth_data)  # Market open
schedule.every().day.at("12:00").do(collect_rth_data)  # Midday
schedule.every().day.at("15:30").do(collect_rth_data)  # Market close

# Run scheduler
while True:
    schedule.run_pending()
    time.sleep(60)
```

================================================================================

## Future Enhancements

### Planned Features
1. **Real-time Data Streaming**: WebSocket integration for live data
2. **Advanced Analytics**: Statistical functions and machine learning integration
3. **API Layer**: REST API for external applications
4. **Web Dashboard**: Real-time visualization dashboard
5. **Alert System**: Price and volume-based alerts

### Scaling Considerations
- **Multi-node Setup**: TimescaleDB clustering for high availability
- **Read Replicas**: Separate read queries from write operations
- **Caching Layer**: Redis for frequently accessed data
- **Load Balancing**: Distribute database connections

================================================================================

## Contact & Support

### Getting Help
1. Check this documentation first
2. Review error logs in Docker container: `docker logs timescaledb`
3. Test connections with provided debugging scripts
4. Check TimescaleDB documentation: https://docs.timescale.com/

### Quick Reference Commands
```bash
# Start database
docker start timescaledb

# Check database status
docker ps | grep timescaledb

# View logs
docker logs timescaledb

# Connect to database
docker exec -it timescaledb psql -U postgres -d momentum_trading

# Run tests
python main/tests/screenerDatabaseTest.py

# Setup database
python main/setup_database.py
```

================================================================================

This documentation covers everything you need to understand, maintain, and extend the TimescaleDB implementation for the HA-Momentum-Trading project. Keep this file updated as the system evolves!

Last Updated: September 22, 2025